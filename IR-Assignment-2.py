# -*- coding: utf-8 -*-
"""IR_Assingment_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fIJnpO7f_nwH5nj-AM26XrHgxTnB9cjn

Shingling
"""

import itertools
import re

#opening and reading the dataset
file = open('human_data.txt')
k = file.read()
#regular expression to preprocess the data removing all non-gene codewords
k =  re.findall('[ATGC]+', k)

docNames = []
for i in range(0, len(k)):
    docID = i
    docNames.append(docID)

#creating a list of shingles for each doc takes shingle length and data as input
def createDocShinglesList(shingle_length, data):
    try:
        s_len = int(shingle_length)  
        d_len = len(data)
    except ValueError:
        return 'Wrong input given'
    else:
        #list of shingles with each cell corresponding to a list of shingles in the corresponding doc
        shingles = []
        for x in data:
            #temporary variable to store shingles of a single docID
            shingle = []

            st_addr = 0
            end_addr = s_len
            while(end_addr < len(x) + 1):
                #if dataset cannot be split into shingles of equal sizes the last unequal shingles are dropped
                if st_addr + s_len > len(x):
                    end_addr = len(x)
                shingle.append(x[st_addr:end_addr])
                st_addr = st_addr + 1
                end_addr = st_addr + s_len
            shingles.append(shingle)
            
    return shingles

#User defines the size of shingles
while True:
    try:
        shingle_length = int(input("\nPlease enter the size of shingles to be made: "))
    except ValueError:
        print("Input invalid. Please enter a positive integer...")
        continue
    if shingle_length <= 0:
        continue
    else:
        break

shingles = createDocShinglesList(shingle_length, k)
chain_object = itertools.chain.from_iterable(shingles)
uniqueShinglesInCorpus = list(chain_object)
uniqueShinglesInCorpus = list(set(uniqueShinglesInCorpus)) 
shingleNo = len(uniqueShinglesInCorpus)

#Printing the shingles generated for docID 0 and the unique shingles in the corpus and their number
#print(shingles[0])
#print(uniqueShinglesInCorpus[0:15])
#print(shingleNo)

"""Minhashing"""

import math 
import random
import time
from time import clock

# Taking user input for number of hash functions
while True:
    try:
        numHashes = int(input("\nPlease enter the number of hash functions to be used: "))
    except ValueError:
        print("Input invalid. Please enter a positive integer...")
        continue
    if numHashes <= 0:
        continue
    else:
        break

print('\nGenerating random hash functions...')

t0 = time.time()

def isPrime(n): 
    if(n <= 1): 
        return False
    if(n <= 3): 
        return True
    if(n % 2 == 0 or n % 3 == 0): 
        return False
    for i in range(5,int(math.sqrt(n) + 1), 6):  
        if(n % i == 0 or n % (i + 2) == 0): 
            return False
    return True
  
# Function to return the smallest prime number greater than N  
def nextPrime(N):
    # Base case  
    if (N <= 1): 
        return 2
    prime = N 
    found = False
    while(not found): 
        prime = prime + 1
        if(isPrime(prime) == True): 
            found = True
    return prime 


# taking total number of shingles    
maxShingleID = shingleNo
nextPrime = nextPrime(shingleNo)

# Random hash functions:  h(x) = (a*x + b) % c
# where a and b are random coefficients, and c is a prime number just greater than the total number of shingles
# x is the shingle index


# Generate list of k unique values mapped to each of the random hash functions
def generateCoefficients(k):
    randList = []
    while k > 0:
      randIndex = random.randint(0, maxShingleID)
      while randIndex in randList:
            randIndex = random.randint(0, maxShingleID)
      randList.append(randIndex)
      k = k - 1
    return randList


# For each hash function, we generate different coefficients a and b.
a = generateCoefficients(numHashes)
b = generateCoefficients(numHashes)

print ('\nGenerating MinHash signatures for all documents...')

# Signature Matrix(signatures/hash codes for docs as elements)
signatures = []

for docID in docNames:
    # Get the shingle set for the current document
    shingleIDSet = shingles[docID]

    # Minhash signature for the current document.
    signature = []

    # For each of the random hash functions, update doc signature if necessary:
    for i in range(0, numHashes):
        #Initialize 'minHashCode' as greater that the maximum possible value output by the hash. (although infinity as taught)
        minHashCode = nextPrime + 1
        
        # For each shingle in the document, calculate its hash code/signature
        for shingleID in range(len(shingleIDSet)):
            hashCode = (a[i] * shingleID + b[i]) % nextPrime
            # Track the lowest hash ID encountered for the document to update
            if hashCode < minHashCode:
                minHashCode = hashCode

        # Add the smallest hash code value as component number 'i' of the doc signature
        signature.append(minHashCode)

    # Store the MinHash signature for this document.
    signatures.append(signature)



# Calculate elapsed time (in seconds)
elapsed = (time.time() - t0)

print ("\nGenerating MinHash signatures took %.4fsec" % elapsed)

#Printing returned signatures 
#print(signatures[0:5])

"""LSH"""

import numpy as np
import pandas as pd
import math
import collections
import time
from operator import itemgetter



#Splitting array into query signature and remaining signatures
def table_rearr(table, s_id):
    base_compare = np.copy(table[:,s_id].reshape(table.shape[0],1))
    table = np.delete(table, s_id, axis = 1)

    return table, base_compare

#comparing given query signature column with other columns in a band and returning a list of lists 
#each can be considered a bucket for a band where signatures match query
def compare(slic, base, s_id):
    #lists of buckets
    bucks = []

    for x in range(slic.shape[1]):
        if all(slic[:,x] == base[:,0]):
            if x < s_id:
                bucks.append(x)
            else:
                bucks.append( x + 1)

    return bucks

#LSH step takes signature matrix as input
def LSH(minhash_t, band, s_id, n_num):

    #converting signature matrix to and numpy array for ease of calculations
    table = minhash_t
    #no. of bands = band
    #no. of rows per band = rowp
    rowp = math.ceil(table.shape[0]/band)
    #list of buckets
    bucket_list = []
    
    if table.shape[0]%band != 0:
        print('Last band has less no. of rows')
        
    
    table, base = table_rearr(table, s_id)
    
    for x in range(band):
        #starting address
        st_addr = x * rowp
        if x == band-1:
            rowp = table.shape[0] - st_addr
        #ending address
        en_addr = st_addr + rowp
        
            
        bucket_list.append(compare(table[st_addr:en_addr, :].reshape(-1,table.shape[1]), base[st_addr:en_addr, :].reshape(-1, 1), s_id))
        #flatenning the list to calcuate frequencies, i.e similarity
        flatten = [item for sublist in bucket_list for item in sublist]
        sim_counter = collections.Counter(flatten)
        #dictionary of docID and their similarity freq (no. of bands the doc is similar to the query)
        sim_counter = dict(sim_counter)
        #returning the n similar docs as tuple pairs
        tup_pair = (sorted(sim_counter.items(), key = itemgetter(1), reverse = True))[:n_num] 
        
    return tup_pair
            
#Printing similarity percentage of n neighbours asked
def similarity(res, band):
    for x in range(len(res)):
        temp = (res[x][1]/band) * 100
        print('Similarity is ' +  str(int(temp)) + '% with docID' + str(res[x][0]))
    return

#precision and recall function for the documents retrieved
def prec_recall(lsh, shing):

    #true positive
    tp = 0

    for x in range(len(shing)):
        for y in range(len(lsh)):
            if lsh[y][0] == shing[x][0]:
                tp += 1
                break

    print(tp)
    #false positive
    fp = len(lsh) - tp

    #false negative
    fn = len(shing) - tp

    #precision
    if tp == 0 and fp == 0:
        precision = 0.0
    else:
        precision = tp/(tp+fp)

    #recall
    recall = tp/(tp+fn)
    
    print('Precision with the given number of bands is:' + str(precision))
    print('Recall with the given number of bands is:' + str(recall))
    
    return

def main_method(minhash_t):
    minhash_t = np.array(minhash_t)
    max_len = minhash_t.shape[0]
    #number of bands to be made passed as user argument
    band = int(input('Enter number of bands to be split into (1 -' + str(max_len) + '): '))

    #shingle id passed as query which user wants to compare
    s_id = int(input('Enter shigle id to calculate similarity: '))

    #number of n similar docs to be found
    n_num = int(input('Enter no. similar docs to be found: '))

    #Time taken for each step lsh and comparing signature one by one
    start = time.time()
    lsh = LSH(minhash_t, band, s_id, n_num)
    #print(lsh)
    l1 = time.time()
    shing = LSH(minhash_t, max_len, s_id, n_num)
    #print(shing)
    l2 = time.time()
    
    #Similarity percentage of each doc and their ID for both LSH and Singaturewise comparison
    print('For Shingle:.....\n')
    similarity(shing, max_len)
    print(f"Time taken to compare each shingle: {l2 - l1}\n")
    
    print('For LSH step:......\n')
    similarity(lsh, band)
    print(f"Time taken for LSH step: {l1 - start}\n")

    #Precision recall calculated based on the assumption that all docs retrieved using single signature comparison are true positives.
    prec_recall(lsh, shing)
    
    return 

#Converting the minhashed signatures into a dataframe, can be used to visualise data better
k = pd.DataFrame(signatures).T
#Calling the main_method function which performs all the steps
main_method(k)



#NOTE: in main_method function the lsh and shing lists can be printed to check similar docs and their frequency
#similarity. List contains tuples of the form (DocID, number of similar signatures in a band[for lsh]/per row[shing])





#Printing the signatures dataframe or signnature of specific docID
#print(k)
#l = k.to_numpy()
#l[:, docID] #//Replace docID with the ID number of the doc you want to print the signature matrix of